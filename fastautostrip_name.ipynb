{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tiChiMzBcXFSmjfsLbUs_BoUk04oI8vf",
      "authorship_tag": "ABX9TyPrQaxyT7nRwu+yfkAPYLDj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NhipCau/FastAutoAudioStrip-Name/blob/main/fastautostrip_name.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GoogleDriveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOR77T50fdW9",
        "outputId": "19706053-66cd-4a35-c1bd-1701e928e5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjV-ZWRJfbrA"
      },
      "outputs": [],
      "source": [
        "#ライブラリをインストール\n",
        "!pip install pydub\n",
        "!pip install openpyxl\n",
        "!pip install webrtcvad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#メインコード\n",
        "import webrtcvad\n",
        "import openpyxl\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# ===== 設定 =====\n",
        "input_audio_path = \"/content/drive/MyDrive/Colab Notebooks/sample_voice.wav\"       # 入力WAVファイル（完全パス）\n",
        "excel_path = \"/content/drive/MyDrive/Colab Notebooks/sample_list.xlsx\"             # Excelファイル（完全パス）\n",
        "output_dir = \"/content/drive/MyDrive/Colab Notebooks/output_wavs\"                  # 出力ディレクトリ（完全パス）\n",
        "\n",
        "target_sample_rate = 48000                  # サンプルレート（Hz）\n",
        "vad_aggressiveness = 3                      # VADの攻撃性（0〜3）\n",
        "#vad_aggressivenessとは？：0 → 息継ぎも含めて「音声」と判定／　3 → 息継ぎや間は「無音」と判定し、2つのチャンクに分割される可能性あり／  1 または 2 がバランスが良く、「誤検出を減らしたい」場合は 2、「できるだけ多くの音声を拾いたい」場合は 1\n",
        "\n",
        "silence_thresh = -55                        # 無音とみなすdB閾値(完全無音は-60db,背景ノイズがある場合は要調整)\n",
        "min_silence_len_ms = 1700                   # 最小サイレンス長（ミリ秒）事前に設定されている無音秒数-前後バッファ秒\n",
        "pre_buffer_sec = 1.5                        # 前バッファ（秒）\n",
        "post_buffer_sec = 1.5                       # 後バッファ（秒）\n",
        "\n",
        "filename_column_index = 1                   # ファイル名を取得する列（A列=0, B列=1, ...）\n",
        "filename_start_row = 4                      # ファイル名を取得する開始行（1行目=0, 2行目=1, ...）\n",
        "\n",
        "# ===== 出力フォルダ作成 =====\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ===== Excelからファイル名を取得 =====\n",
        "wb = openpyxl.load_workbook(excel_path)\n",
        "sheet = wb.active\n",
        "filenames = [\n",
        "    row[filename_column_index]\n",
        "    for row in sheet.iter_rows(min_row=filename_start_row, values_only=True)\n",
        "    if row[filename_column_index]\n",
        "]\n",
        "\n",
        "# ===== 音声読み込みとサンプルレート変換 =====\n",
        "audio = AudioSegment.from_wav(input_audio_path)\n",
        "audio = audio.set_channels(1).set_frame_rate(target_sample_rate).set_sample_width(2)\n",
        "\n",
        "# ===== webrtcvad用に生データを準備 =====\n",
        "raw_audio = audio.raw_data\n",
        "frame_duration = 30  # ms\n",
        "frame_size = int(target_sample_rate * frame_duration / 1000) * 2  # 2 bytes/sample\n",
        "\n",
        "frames = [\n",
        "    (i * frame_duration, raw_audio[i * frame_size:(i + 1) * frame_size])\n",
        "    for i in range(len(raw_audio) // frame_size)\n",
        "]\n",
        "\n",
        "# ===== VADで音声区間を検出 =====\n",
        "vad = webrtcvad.Vad(vad_aggressiveness)\n",
        "speech_segments = []\n",
        "is_speech = False\n",
        "segment_start = 0\n",
        "\n",
        "for i, (timestamp, frame) in enumerate(frames):\n",
        "    if len(frame) < frame_size:\n",
        "        break\n",
        "    if vad.is_speech(frame, target_sample_rate):\n",
        "        if not is_speech:\n",
        "            segment_start = timestamp\n",
        "            is_speech = True\n",
        "    else:\n",
        "        if is_speech:\n",
        "            segment_end = timestamp\n",
        "            speech_segments.append((segment_start, segment_end))\n",
        "            is_speech = False\n",
        "\n",
        "if is_speech:\n",
        "    speech_segments.append((segment_start, timestamp + frame_duration))\n",
        "\n",
        "# ===== dB閾値でフィルタリング =====\n",
        "filtered_segments = []\n",
        "for start_ms, end_ms in speech_segments:\n",
        "    segment = audio[start_ms:end_ms]\n",
        "    if segment.dBFS >= silence_thresh:\n",
        "        filtered_segments.append((start_ms, end_ms))\n",
        "\n",
        "# ===== 最小サイレンス長でマージ =====\n",
        "merged_segments = []\n",
        "if filtered_segments:\n",
        "    current_start, current_end = filtered_segments[0]\n",
        "    for start_ms, end_ms in filtered_segments[1:]:\n",
        "        if start_ms - current_end < min_silence_len_ms:\n",
        "            current_end = end_ms\n",
        "        else:\n",
        "            merged_segments.append((current_start, current_end))\n",
        "            current_start, current_end = start_ms, end_ms\n",
        "    merged_segments.append((current_start, current_end))\n",
        "\n",
        "# ===== バッファを加えて保存 =====\n",
        "pre_buffer_ms = int(pre_buffer_sec * 1000)\n",
        "post_buffer_ms = int(post_buffer_sec * 1000)\n",
        "\n",
        "for i, (start_ms, end_ms) in enumerate(merged_segments):\n",
        "    if i < len(filenames):\n",
        "        start = max(0, start_ms - pre_buffer_ms)\n",
        "        end = min(len(audio), end_ms + post_buffer_ms)\n",
        "        chunk = audio[start:end]\n",
        "        output_path = os.path.join(output_dir, f\"{filenames[i]}.wav\")\n",
        "        chunk.export(output_path, format=\"wav\")\n",
        "        print(f\"保存しました: {output_path}\")\n",
        "    else:\n",
        "        print(f\"ファイル名が不足しています（チャンク{i+1}）\")\n",
        "\n",
        "print(\"処理が完了しました。\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NBQNlSm_fqHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q12E4I8pgqQg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}